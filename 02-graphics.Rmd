# Time series graphics {#graphics}

\index{time series graphics|(}

The first thing to do in any data analysis task is to plot the data. Graphs enable many features of the data to be visualised, including patterns, unusual observations, changes over time, and relationships between variables. The features that are seen in plots of the data must then be incorporated, as much as possible, into the forecasting methods to be used. Just as the type of data determines what forecasting method to use, it also determines what graphs are appropriate. But before we produce graphs, we need to set up our time series in R.

## `tsibble` objects {#tsibbles}

A time series\index{time series data} can be thought of as a list of numbers (the measurements), along with some information about what times those numbers were recorded (the index).\index{index variable} This information can be stored as a `tsibble` object in R.\index{tsibble objects@\texttt{tsibble} objects|(}

### The index variable {-}

Suppose you have annual observations for the last few years:\index{index variable}

```{r tstable, echo=FALSE}
x <- c(123, 39, 78, 52, 110)
yr <- 2015:2019
knitr::kable(tibble(Year = yr, Observation = x), booktabs = TRUE)
```

We turn this into a `tsibble` object using the `tsibble()` function:\index{tsibble@\texttt{tsibble()}}

```{r first-tsibble}
y <- tsibble(
  Year = 2015:2019,
  Observation = c(123, 39, 78, 52, 110),
  index = Year
)
```

`tsibble` objects\index{tsibble objects@\texttt{tsibble} objects} extend tidy data frames (`tibble` objects) by introducing temporal structure. We have set the time series `index` to be the `Year` column, which associates the measurements (`Observation`) with the time of recording (`Year`).

For observations that are more frequent than once per year, we need to use a time class function on the index. For example, suppose we have a monthly dataset `z`: \index{monthly data}

```{r tstablemonth, echo=FALSE}
z <- tibble(Month = paste(2019, month.abb[1:5]), Observation = c(50, 23, 34, 30, 25))
# knitr::kable(z, booktabs=TRUE)
```

```{r tstablemonth2}
z
```

This can be converted to a `tsibble` object using the following code:\index{mutate@\texttt{mutate()}}

```{r month-tsibble}
z %>%
  mutate(Month = yearmonth(Month)) %>%
  as_tsibble(index = Month)
```

First, the `Month` column is being converted from text to a monthly time object with `yearmonth()`. We then convert the data frame to a `tsibble` by identifying the `index` variable using `as_tsibble()`. Note the addition of "[1M]" on the first line indicating this is monthly data.

Other time class functions can be used depending on the frequency of the observations.\index{index variable}

```{r tstable2, echo=FALSE, results=ifelse(html, 'markup', 'asis')}
tab <- tribble(
    ~`Frequency`, ~Function,
    "Annual", "`start:end`",
    "Quarterly", "`yearquarter()`",
    "Monthly", "`yearmonth()`",
    "Weekly", "`yearweek()`",
    "Daily", "`as_date()`, `ymd()`",
    "Sub-daily", "`as_datetime()`, `ymd_hms()`"
  )
if(!html) {
  tab <- tab %>%
    mutate(
      Function = stringr::str_replace(Function, "`","\\\\texttt{"),
      Function = stringr::str_replace(Function, "`, `","}, \\\\texttt{"),
      Function = stringr::str_replace(Function, "`","}"),
      Function = stringr::str_replace_all(Function,"_","\\\\_")
    )
}
tab %>% knitr::kable(booktabs = TRUE, escape=html)
```

### The key variables {-}

A `tsibble` also\index{tsibble objects@\texttt{tsibble} objects} allows multiple time series to be stored in a single object. Suppose you are interested in a dataset containing the fastest running times for women's and men's track races at the Olympics, from 100m to 10000m:\index{key variable}

```{r tstablekey}
olympic_running
```

The summary above shows that this is a `tsibble` object, which contains 312 rows and 4 columns. Alongside this, "[4Y]" informs us that the interval of these observations is every four years. Below this is the key structure, which informs us that there are 14 separate time series in the `tsibble`. A preview of the first 10 observations is also shown, in which we can see a missing value occurs in 1916. This is because the Olympics were not held during World War I.

The 14 time series in this object are uniquely identified by the keys: the `Length` and `Sex` variables. The `distinct()` function\index{distinct@\texttt{distinct()}} can be used to show the categories of each variable or even combinations of variables:

```{r distinctfn}
olympic_running %>% distinct(Sex)
```

### Working with `tsibble` objects {-}

We can use `dplyr` functions\index{dplyr functions@\texttt{dplyr} functions} \index{mutate@\texttt{mutate()}}\index{filter@\texttt{filter()}}\index{select@\texttt{select()}}\index{summarise@\texttt{summarise()}} such as `mutate()`, `filter()`, `select()` and `summarise()` to work with `tsibble` objects.\index{tsibble objects@\texttt{tsibble} objects} To illustrate these, we will use the `PBS` tsibble containing sales data on pharmaceutical products in Australia.

```{r pbs1}
PBS
```

This contains monthly data on Medicare Australia prescription data from July 1991 to June 2008. These are classified according to various concession types, and Anatomical Therapeutic Chemical (ATC) indexes. For this example, we are interested in the `Cost` time series (total cost of scripts in Australian dollars).

We can use the `filter()` function\index{filter@\texttt{filter()}} to extract the A10 scripts:

```{r pbs2}
PBS %>%
  filter(ATC2 == "A10")
```

This allows rows of the tsibble to be selected. Next we can simplify the resulting object by selecting the columns we will need in subsequent analysis.

```{r pbs3}
PBS %>%
  filter(ATC2 == "A10") %>%
  select(Month, Concession, Type, Cost)
```

The `select()` function allows us to select particular columns, while `filter()` allows us to keep particular rows.

Note that the index variable `Month`, and the keys `Concession` and `Type`, would be returned even if they were not explicitly selected as they are required for a tsibble (to ensure each row contains a unique combination of keys and index).

Another useful function is `summarise()` which allows us to combine data across keys. For example, we may wish to compute total cost per month regardless of the `Concession` or `Type` keys.

\enlargethispage*{-0.4cm}

```{r pbs4}
PBS %>%
  filter(ATC2 == "A10") %>%
  select(Month, Concession, Type, Cost) %>%
  summarise(TotalC = sum(Cost))
```

The new variable `TotalC` is the sum of all `Cost` values for each month.

We can create new variables using the `mutate()` function\index{mutate@\texttt{mutate()}}. Here we change the units from dollars to millions of dollars:

```{r pbs5}
PBS %>%
  filter(ATC2 == "A10") %>%
  select(Month, Concession, Type, Cost) %>%
  summarise(TotalC = sum(Cost)) %>%
  mutate(Cost = TotalC/1e6)
```

Finally, we will save the resulting tsibble for examples later in this chapter.

```{r a10}
PBS %>%
  filter(ATC2 == "A10") %>%
  select(Month, Concession, Type, Cost) %>%
  summarise(TotalC = sum(Cost)) %>%
  mutate(Cost = TotalC / 1e6) -> a10
```

At the end of this series of piped functions, we have used a right assignment (`->`), which is not common in R code, but is convenient at the end of a long series of commands as it continues the flow of the code.

### Read a csv file and convert to a tsibble {-}

Almost all of the data used in this book is already stored as `tsibble` objects\index{tsibble objects@\texttt{tsibble} objects}. But most data lives in databases, MS-Excel files or csv files, before it is imported into R. So often the first step in creating a tsibble is to read in the data, and then identify the index and key variables.

For example, suppose we have the following quarterly data stored in a csv file (only the first 10 rows are shown). This data set provides information on the size of the prison population in Australia, disaggregated by state, gender, legal status and indigenous status. (Here, ATSI stands for Aboriginal or Torres Strait Islander.)

```{r prison, echo=FALSE, warning=FALSE, message=FALSE, eval=TRUE}
prison <- readr::read_csv("extrafiles/prison_population.csv")
prison %>%
  head(10) %>%
  knitr::kable(booktabs = TRUE)
```

We can read it into R, and create a tsibble object, by simply identifying which column contains the time index, and which columns are keys. The remaining columns are values --- there can be many value columns, although in this case there is only one (`Count`). The original csv file stored the dates as individual days, although the data is actually quarterly, so we need to convert the `Date` variable to quarters.\index{tsibble objects@\texttt{tsibble} objects}

```{r loadprison_html, echo=html, eval=FALSE}
prison <- readr::read_csv("https://OTexts.com/fpp3/extrafiles/prison_population.csv")
```

```{r loadprison_latex, echo=!html, eval=FALSE}
prison <- readr::read_csv("https://OTexts.com/fpp3/extrafiles/
                                      prison_population.csv")
```

```{r prison2, dependson='prison'}
prison <- prison %>%
  mutate(Quarter = yearquarter(Date)) %>%
  select(-Date) %>%
  as_tsibble(key = c(State, Gender, Legal, Indigenous),
             index = Quarter)

prison
```

This tsibble contains 64 separate time series corresponding to the combinations of the 8 states, 2 genders, 2 legal statuses and 2 indigenous statuses. Each of these series is `r NROW(prison)/64` observations in length, from `r head(prison,1)$Quarter` to `r tail(prison,1)$Quarter`.

For a tsibble to be valid, it requires a unique index for each combination of keys. The `tsibble()` or `as_tsibble()` function\index{tsibble@\texttt{tsibble()}} will return an error if this is not true.

### The seasonal period {-}
<!-- TODO: Also detail problematic periods (months in daily data). -->

Some graphics and some models will use the seasonal period of the data. The seasonal period\index{seasonal period} is the number of observations before the seasonal pattern repeats. In most cases, this will be automatically detected using the time index variable.

Some common periods for different time intervals are shown in the table below:

```{r freqtable, echo=FALSE, message=FALSE}
intervals <- list(
  Quarters = tsibble::new_interval(quarter = 1),
  Months = tsibble::new_interval(month = 1),
  Weeks = tsibble::new_interval(week = 1),
  Days = tsibble::new_interval(day = 1),
  Hours = tsibble::new_interval(hour = 1),
  Minutes = tsibble::new_interval(minute = 1),
  Seconds = tsibble::new_interval(second = 1)
)

intervals %>%
  purrr::map(common_periods) %>%
  purrr::map(as.list) %>%
  purrr::map_dfr(as_tibble, .id = "Data") %>%
  purrr::set_names(., stringr::str_to_sentence(colnames(.))) %>%
  select(Data, Minute, Hour, Day, Week, Year) %>%
  mutate_all(format, scientific = FALSE, nsmall = 2) %>%
  mutate_all(~ gsub(".00", "", ., fixed = TRUE)) %>%
  mutate_all(~ gsub("   NA", "", ., fixed = TRUE)) %>%
  knitr::kable(booktabs = TRUE)
```

For quarterly, monthly and weekly data, there is only one seasonal period --- the number of observations within each year. Actually, there are not $52$ weeks in a year, but $365.25/7 = `r sprintf("%.2f",365.25/7)`$ on average, allowing for a leap year every fourth year. Approximating seasonal periods to integers can be useful as many seasonal terms in models only support integer seasonal periods.\index{seasonal period}

If the data is observed more than once per week, then there is often more than one seasonal pattern in the data. For example, data with daily observations\index{daily data} might have weekly (period$=7$) or annual (period$=365.25$) seasonal patterns. Similarly, data that are observed every minute might have hourly (period$=60$), daily (period$=24\times60=1440$), weekly (period$=24\times60\times7=10080$) and annual seasonality (period$=24\times60\times365.25=525960$).\index{hourly data}\index{multiple seasonality}\index{sub-daily data}\index{seasonal period}

More complicated (and unusual) seasonal patterns can be specified using the `period()` function in the `lubridate` package.\index{tsibble objects@\texttt{tsibble} objects|)}

## Time plots

For time series data, the obvious graph to start with is a time\index{time plots} plot. That is, the observations are plotted against the time of observation, with consecutive observations joined by straight lines. Figure \@ref(fig:ansett) shows the weekly economy passenger load on Ansett airlines between Australia's two largest cities.

```{r ansett, fig.cap="Weekly economy passenger load on Ansett Airlines."}
melsyd_economy <- ansett %>%
  filter(Airports == "MEL-SYD", Class == "Economy") %>%
  mutate(Passengers = Passengers/1000)
autoplot(melsyd_economy, Passengers) +
  labs(title = "Ansett airlines economy class",
       subtitle = "Melbourne-Sydney",
       y = "Passengers ('000)")
```

We will use the `autoplot()`\index{autoplot@\texttt{autoplot()}} command frequently. It automatically produces an appropriate plot of whatever you pass to it in the first argument. In this case, it recognises `melsyd_economy` as a time series and produces a time plot.

The time plot immediately reveals some interesting features.

-   There was a period in 1989 when no passengers were carried --- this was due to an industrial dispute.
-   There was a period of reduced load in 1992. This was due to a trial in which some economy class seats were replaced by business class seats.
-   A large increase in passenger load occurred in the second half of 1991.
-   There are some large dips in load around the start of each year. These are due to holiday effects.
-   There is a long-term fluctuation in the level of the series which increases during 1987, decreases in 1989, and increases again through 1990 and 1991.

Any model will need to take all these features into account in order to effectively forecast the passenger load into the future.

A simpler time series is shown in Figure \@ref(fig:a10plot), using the `a10` data saved earlier.

```{r a10plot, fig.cap="Monthly sales of antidiabetic drugs in Australia.", dependson='a10'}
autoplot(a10, Cost) +
  labs(y = "$ (millions)",
       title = "Australian antidiabetic drug sales")
```

Here, there is a clear and increasing trend. There is also a strong seasonal pattern that increases in size as the level of the series increases. The sudden drop at the start of each year is caused by a government subsidisation scheme that makes it cost-effective for patients to stockpile drugs at the end of the calendar year. Any forecasts of this series would need to capture the seasonal pattern, and the fact that the trend is changing slowly.

## Time series patterns {#tspatterns}

In describing these time series, we have used words such as "trend" and "seasonal" which need to be defined more carefully.

Trend\index{trend}
  : A *trend* exists when there is a long-term increase or decrease in the data. It does not have to be linear. Sometimes we will refer to a trend as "changing direction", when it might go from an increasing trend to a decreasing trend. There is a trend in the antidiabetic drug sales data shown in Figure \@ref(fig:a10plot).

Seasonal\index{seasonality}
  : A *seasonal* pattern occurs when a time series is affected by seasonal factors such as the time of the year or the day of the week. Seasonality is always of a fixed and known period. The monthly sales of antidiabetic drugs (Figure \@ref(fig:a10plot)) shows seasonality which is induced partly by the change in the cost of the drugs at the end of the calendar year.

Cyclic\index{cycles}
  : A *cycle* occurs when the data exhibit rises and falls that are not of a fixed frequency. These fluctuations are usually due to economic conditions, and are often related to the "business cycle". The duration of these fluctuations is usually at least 2 years.

Many people confuse cyclic behaviour with seasonal behaviour, but they are really quite different. If the fluctuations are not of a fixed frequency then they are cyclic; if the frequency is unchanging and associated with some aspect of the calendar, then the pattern is seasonal. In general, the average length of cycles is longer than the length of a seasonal pattern, and the magnitudes of cycles tend to be more variable than the magnitudes of seasonal patterns.

Many time series include trend, cycles and seasonality.\index{seasonality}\index{cycles} When choosing a forecasting method, we will first need to identify the time series patterns in the data, and then choose a method that is able to capture the patterns properly.

The examples in Figure \@ref(fig:fourexamples) show different combinations of these components.

```{r fourexamples, echo=FALSE, fig.cap="Four examples of time series showing different patterns.", fig.env="figure*", warning = FALSE, message=FALSE}
smallfonts <- theme(
  text = element_text(size = 9),
  axis.text = element_text(size = 8)
)
p1 <- fma::hsales %>%
  as_tsibble() %>%
  autoplot(value) + smallfonts +
  labs(y = "Houses (millions)", title = "Sales of new one-family houses, USA")
p2 <- fma::ustreas %>%
  as_tsibble() %>%
  autoplot(value) + smallfonts +
  labs(x = "Day", y = "Number", title = "US treasury bill contracts")
p3 <- aus_production %>%
  autoplot(Electricity) + smallfonts +
  labs(y = "kWh (billion) ", title = "Australian quarterly electricity production")
p4 <- gafa_stock %>%
  filter(Symbol == "GOOG") %>%
  autoplot(difference(Close)) + smallfonts +
  labs(y = "$US", title = "Daily changes in Google closing stock price")

(p1 | p2) / (p3 | p4)
```

  1. The monthly housing sales (top left) show strong seasonality within each year, as well as some strong cyclic behaviour with a period of about 6--10 years. There is no apparent trend in the data over this period.
  2. The US treasury bill contracts (top right) show results from the Chicago market for 100 consecutive trading days in 1981. Here there is no seasonality, but an obvious downward trend. Possibly, if we had a much longer series, we would see that this downward trend is actually part of a long cycle, but when viewed over only 100 days it appears to be a trend.
  3. The Australian quarterly electricity production (bottom left) shows a strong increasing trend, with strong seasonality. There is no evidence of any cyclic behaviour here.
  4. The daily change in the Google closing stock price (bottom right) has no trend, seasonality or cyclic behaviour. There are random fluctuations which do not appear to be very predictable, and no strong patterns that would help with developing a forecasting model.

## Seasonal plots

A seasonal plot\index{seasonal plot|(} is similar to a time plot except that the data are plotted against the individual "seasons" in which the data were observed. An example is given in Figure \@ref(fig:seasonplot1) showing the antidiabetic drug sales.\index{gg\_season@\texttt{gg\_season()}}

```{r seasonplot1code, eval=FALSE}
a10 %>%
  gg_season(Cost, labels = "both") +
  labs(y = "$ (millions)",
       title = "Seasonal plot: Antidiabetic drug sales")
```

```{r seasonplot1, fig.cap="Seasonal plot of monthly antidiabetic drug sales in Australia.", dependson='a10', warning=FALSE, echo=FALSE}
a10 %>%
  gg_season(Cost, labels = "both") +
  labs(y = "$ (millions)",
       title = "Seasonal plot: Antidiabetic drug sales") +
  expand_limits(x = ymd(c("1972-12-28", "1973-12-04")))
```

These are exactly the same data as were shown earlier, but now the data from each season are overlapped. A seasonal plot allows the underlying seasonal pattern to be seen more clearly, and is especially useful in identifying years in which the pattern changes.

In this case, it is clear that there is a large jump in sales in January each year. Actually, these are probably sales in late December as customers stockpile before the end of the calendar year, but the sales are not registered with the government until a week or two later. The graph also shows that there was an unusually small number of sales in March 2008 (most other years show an increase between February and March). The small number of sales in June 2008 is probably due to incomplete counting of sales at the time the data were collected.

### Multiple seasonal periods {-}

Where the data has more than one seasonal pattern,\index{multiple seasonality} the `period` argument can be used to select which seasonal plot is required.  The `vic_elec` data contains half-hourly electricity demand\index{electricity demand} for the state of Victoria, Australia. We can plot the daily pattern, weekly pattern or yearly pattern by specifying the `period` argument as shown in Figures \@ref(fig:multipleseasonplots1)--\@ref(fig:multipleseasonplots3).

In the first plot, the three days with 25 hours are when daylight saving ended in each year and so these days contained an extra hour. There were also three days with only 23 hours each (when daylight saving started) but these are hidden beneath all the other lines on the plot.

```{r multipleseasonplots1, warning=FALSE, fig.cap="Seasonal plot showing daily seasonal patterns for Victorian electricity demand.", fig.asp=0.6}
vic_elec %>% gg_season(Demand, period = "day") +
  theme(legend.position = "none") +
  labs(y="MWh", title="Electricity demand: Victoria")
```

```{r multipleseasonplots2, warning=FALSE, fig.cap="Seasonal plot showing weekly seasonal patterns for Victorian electricity demand.", fig.asp=0.6}
vic_elec %>% gg_season(Demand, period = "week") +
  theme(legend.position = "none") +
  labs(y="MWh", title="Electricity demand: Victoria")
```

```{r multipleseasonplots3, warning=FALSE, fig.cap="Seasonal plot showing yearly seasonal patterns for Victorian electricity demand.", fig.asp=0.6}
vic_elec %>% gg_season(Demand, period = "year") +
  labs(y="MWh", title="Electricity demand: Victoria")
```

\index{seasonal plot|)}\index{electricity demand}\newpage

## Seasonal subseries plots {#subseries}

An alternative plot that emphasises the seasonal patterns is where the data for each season are collected together in separate mini time plots.\index{seasonal subseries plot|(}\index{gg\_subseries@\texttt{gg\_subseries()}}

```{r subseriesplot, fig.cap="Seasonal subseries plot of monthly antidiabetic drug sales in Australia.", dependson='a10', fig.height=3, fig.width=8, fig.asp=0.375, warning=FALSE}
a10 %>%
  gg_subseries(Cost) +
  labs(
    y = "$ (millions)",
    title = "Australian antidiabetic drug sales"
  )
```

The blue horizontal lines indicate the means for each month. This form of plot enables the underlying seasonal pattern to be seen clearly, and also shows the changes in seasonality over time. It is especially useful in identifying changes within particular seasons. In this example, the plot is not particularly revealing; but in some cases, this is the most useful way of viewing seasonal changes over time.

### Example: Australian holiday tourism {-}

Australian quarterly vacation data provides an interesting example of how these plots can reveal information. First we need to extract the relevant data from the `tourism` tsibble. All the usual `tidyverse`\index{tidyverse packages@\texttt{tidyverse} packages} wrangling verbs apply. To get the total visitor nights spent on Holiday by State for each quarter (i.e., ignoring Regions) we can use the following code. Note that we do not have to explicitly group by the time index as this is required in a `tsibble`.

```{r holidays}
holidays <- tourism %>%
  filter(Purpose == "Holiday") %>%
  group_by(State) %>%
  summarise(Trips = sum(Trips))
```

```{r holidaysprint}
holidays
```

Time plots of each series show that there is strong seasonality for most states, but that the seasonal peaks do not coincide.

```{r holidays-plot, echo=TRUE, dependson="holidays", fig.height=3.9, fig.asp=0.5, fig.cap="Time plots of Australian domestic holidays by state."}
autoplot(holidays, Trips) +
  labs(y = "Overnight trips ('000)",
       title = "Australian domestic holidays")
```

To see the timing of the seasonal peaks in each state, we can use a season plot. Figure \@ref(fig:holidaysseason) makes it clear that the southern states of Australia (Tasmania, Victoria and South Australia) have strongest tourism in Q1 (their summer), while the northern states (Queensland and the Northern Territory) have the strongest tourism in Q3 (their dry season).

```{r holidaysseason, fig.height=9, fig.asp=1.3, fig.cap="Season plots of Australian domestic holidays by state.", warning=FALSE}
gg_season(holidays, Trips) +
  labs(y = "Overnight trips ('000)",
       title = "Australian domestic holidays")
```

\newpage

The corresponding subseries plots are shown in Figure \@ref(fig:holidayssubseries).

```{r holidayssubseries, fig.height=10, fig.width=8, fig.asp=1.3, fig.cap="Subseries plots of Australian domestic holidays by state.", warning=FALSE}
holidays %>%
  gg_subseries(Trips) +
  labs(y = "Overnight trips ('000)",
       title = "Australian domestic holidays")
```

This figure makes it evident that Western Australian tourism has jumped markedly in recent years, while Victorian tourism has increased in Q1 and Q4 but not in the middle of the year.\index{seasonal subseries plot|)}

\newpage

## Scatterplots

The graphs discussed so far are useful for visualising individual time series. It is also useful to explore relationships *between* time series.\index{scatterplots|(}

Figures \@ref(fig:edemand) and \@ref(fig:victemp) show two time series: half-hourly electricity demand\index{electricity demand} (in Gigawatts) and temperature (in degrees Celsius), for 2014 in Victoria, Australia. The temperatures are for Melbourne, the largest city in Victoria, while the demand values are for the entire state.

\newpage

```{r edemand, fig.cap="Half hourly electricity demand in Victoria, Australia, for 2014.", fig.height=2.5, fig.asp=0.45}
vic_elec %>%
  filter(year(Time) == 2014) %>%
  autoplot(Demand) +
  labs(y = "GW",
       title = "Half-hourly electricity demand: Victoria")
```

```{r victemp, fig.cap="Half hourly temperature in Melbourne, Australia, for 2014.", fig.height=2.5, fig.asp=0.45}
vic_elec %>%
  filter(year(Time) == 2014) %>%
  autoplot(Temperature) +
  labs(
    y = "Degrees Celsius",
    title = "Half-hourly temperatures: Melbourne, Australia"
  )
```

We can study the relationship between demand and temperature by plotting one series against the other.

```{r edemand2, fig.cap="Half-hourly electricity demand plotted against temperature for 2014 in Victoria, Australia."}
vic_elec %>%
  filter(year(Time) == 2014) %>%
  ggplot(aes(x = Temperature, y = Demand)) +
  geom_point() +
  labs(x = "Temperature (degrees Celsius)",
       y = "Electricity demand (GW)")
```

This scatterplot helps us to visualise the relationship between the variables. It is clear that high demand occurs when temperatures are high due to the effect of air-conditioning. But there is also a heating effect, where demand increases for very low temperatures.\index{electricity demand}

### Correlation {-}

It is common to compute *correlation coefficients* to measure the strength of the linear relationship between two variables. The correlation between variables $x$ and $y$ is given by\index{correlation}
\[
r = \frac{\sum (x_{t} - \bar{x})(y_{t}-\bar{y})}{\sqrt{\sum(x_{t}-\bar{x})^2}\sqrt{\sum(y_{t}-\bar{y})^2}}.
\]
The value of $r$ always lies between $-1$ and 1 with negative values indicating a negative relationship and positive values indicating a positive relationship. The graphs in Figure \@ref(fig:corr) show examples of data sets with varying levels of correlation.

```{r corr, fig.cap="Examples of data sets with different levels of correlation.", echo=FALSE, warning=FALSE, message=FALSE, fig.width=10, fig.height=4.5, fig.asp=0.55}
corplot <- function(rho) {
  library(mvtnorm)
  x <- rmvnorm(100, sigma = matrix(c(1, rho, rho, 1), 2, 2))
  ggplot(as.data.frame(x), aes(x = V1, y = V2)) +
    geom_point() +
    labs(
      x = "",
      y = "",
      title = paste("Correlation =", sprintf("%.2f", rho))
    ) +
    xlim(-3.5, 3.5) +
    ylim(-3.5, 3.5)
}
set.seed(12345)
p1 <- corplot(-0.99)
p2 <- corplot(-0.75)
p3 <- corplot(-0.5)
p4 <- corplot(-0.25)
p5 <- corplot(0.99)
p6 <- corplot(0.75)
p7 <- corplot(0.5)
p8 <- corplot(0.25)

(p1 | p2 | p3 | p4) / (p5 | p6 | p7 | p8)
```

```{r eleccorrelation, include=FALSE}
x <- vic_elec %>% filter(year(Time) == 2014)
eleccor <- cor(x$Temperature, x$Demand)
```

The correlation coefficient only measures the strength of the *linear* relationship between two variables, and can sometimes be misleading. For example, the correlation for the electricity demand and temperature data shown in Figure \@ref(fig:edemand2) is `r round(eleccor,2)`, but the *non-linear* relationship is stronger than that.

(ref:anscombe) Each of these plots has a correlation coefficient of 0.82. Data from @Anscombe1973graphs.

```{r anscombe, fig.cap="(ref:anscombe)", echo=FALSE, fig.asp=1, out.width="55%", fig.height=4,fig.width=4}
p1 <- ggplot(anscombe, aes(x = x1, y = y1)) +
  geom_point() +
  labs(x = "x", y = "y")
p2 <- ggplot(anscombe, aes(x = x2, y = y2)) +
  geom_point() +
  labs(x = "x", y = "y")
p3 <- ggplot(anscombe, aes(x = x3, y = y3)) +
  geom_point() +
  labs(x = "x", y = "y")
p4 <- ggplot(anscombe, aes(x = x4, y = y4)) +
  geom_point() +
  labs(x = "x", y = "y")
(p1 | p2) / (p3 | p4)
```

The plots in Figure \@ref(fig:anscombe) all have correlation coefficients of 0.82, but they have very different relationships. This shows how important it is to look at the plots of the data and not simply rely on correlation values.\index{correlation}

### Scatterplot matrices {-}

When there are several potential predictor variables, it is useful to plot each variable against each other variable. Consider the eight time series shown in Figure \@ref(fig:vntimeplots), showing quarterly visitor numbers across states and territories of Australia.\index{scatterplot matrices}

```{r vntimeplots, fig.cap="Quarterly visitor nights for the states and territories of Australia.", fig.asp=1.3, out.width="100%"}
visitors <- tourism %>%
  group_by(State) %>%
  summarise(Trips = sum(Trips))
visitors %>%
  ggplot(aes(x = Quarter, y = Trips)) +
  geom_line() +
  facet_grid(vars(State), scales = "free_y") +
  labs(title = "Australian domestic tourism",
       y= "Overnight trips ('000)")
```

\newpage

To see the relationships between these eight time series, we can plot each time series against the others. These plots can be arranged in a scatterplot matrix, as shown in Figure \@ref(fig:ScatterMatrixch2).\index{ggpairs@\texttt{ggpairs()}} (This plot requires the `GGally` package to be installed.)

```{r ScatterMatrixch2, fig.cap="A scatterplot matrix of the quarterly visitor nights in the states and territories of Australia.", fig.asp=1, fig.height=10, fig.width=10, out.width="100%", message=FALSE, fig.env="figure*"}
visitors %>%
  pivot_wider(values_from=Trips, names_from=State) %>%
  GGally::ggpairs(columns = 2:9)
```

For each panel, the variable on the vertical axis is given by the variable name in that row, and the variable on the horizontal axis is given by the variable name in that column. There are many options available to produce different plots within each panel. In the default version, the correlations are shown in the upper right half of the plot, while the scatterplots are shown in the lower half. On the diagonal are shown density plots.

The value of the scatterplot matrix is that it enables a quick view of the relationships between all pairs of variables. In this example, mostly positive relationships are revealed, with the strongest relationships being between the neighbouring states located in the south and south east coast of Australia, namely, New South Wales, Victoria and South Australia. Some negative relationships are also revealed between the Northern Territory and other regions. The Northern Territory is located in the north of Australia famous for its outback desert landscapes visited mostly in winter. Hence, the peak visitation in the Northern Territory is in the July (winter) quarter in contrast to January (summer) quarter for the rest of the regions.\index{scatterplots|)}

## Lag plots

Figure \@ref(fig:beerlagplot) displays scatterplots of quarterly Australian beer production (introduced in Figure \@ref(fig:beer)), where the horizontal axis shows lagged values of the time series. Each graph shows $y_{t}$ plotted against $y_{t-k}$ for different values of $k$.\index{lag plots}\index{gg\_lag@\texttt{gg\_lag()}}

```{r beerlagplot, fig.cap="Lagged scatterplots for quarterly beer production.", fig.asp=1}
recent_production <- aus_production %>%
  filter(year(Quarter) >= 2000)
recent_production %>%
  gg_lag(Beer, geom = "point") +
  labs(x = "lag(Beer, k)")
```

Here the colours indicate the quarter of the variable on the vertical axis. The relationship is strongly positive at lags 4 and 8, reflecting the strong seasonality in the data. The negative relationship seen for lags 2 and 6 occurs because peaks (in Q4) are plotted against troughs (in Q2)

## Autocorrelation {#acf}

Just as correlation measures the extent of a linear relationship between two variables, autocorrelation measures the linear relationship between *lagged values* of a time series.\index{autocorrelation}

There are several autocorrelation coefficients, corresponding to each panel in the lag plot. For example, $r_{1}$ measures the relationship between $y_{t}$ and $y_{t-1}$, $r_{2}$ measures the relationship between $y_{t}$ and $y_{t-2}$, and so on.

The value of $r_{k}$ can be written as
$$
 r_{k} = \frac{\sum\limits_{t=k+1}^T (y_{t}-\bar{y})(y_{t-k}-\bar{y})}
 {\sum\limits_{t=1}^T (y_{t}-\bar{y})^2},
$$
where $T$ is the length of the time series. The autocorrelation coefficients make up the *autocorrelation function* or ACF.

The autocorrelation coefficients for the beer production data can be computed using the `ACF()` function.\index{autocorrelation}\index{ACF@\texttt{ACF()}}

```{r beeracfraw, dependson='beerlagplot'}
recent_production %>% ACF(Beer, lag_max = 9)
```

The values in the `acf` column are $r_1,\dots,r_9$, corresponding to the nine scatterplots in Figure \@ref(fig:beerlagplot). We usually plot the ACF to see how the correlations change with the lag $k$. The plot is sometimes known as a *correlogram*.\index{autocorrelation}\index{ACF@\texttt{ACF()}}\index{autoplot@\texttt{autoplot()}}

```{r beeracf, fig.cap="Autocorrelation function of quarterly beer production.", fig.asp=0.3, dependson="beerlagplot"}
recent_production %>%
  ACF(Beer) %>%
  autoplot() + labs(title="Australian beer production")
```

\newpage

In this\index{autocorrelation} graph:

-   $r_{4}$ is higher than for the other lags. This is due to the seasonal pattern in the data: the peaks tend to be four quarters apart and the troughs tend to be four quarters apart.
-   $r_{2}$ is more negative than for the other lags because troughs tend to be two quarters behind peaks.
-   The dashed blue lines indicate whether the correlations are significantly different from zero (as explained in Section \@ref(wn)).

### Trend and seasonality in ACF plots {-}

When data have a trend,\index{trend} the autocorrelations for small lags tend to be large and positive because observations nearby in time are also nearby in value. So the ACF of a trended time series tends to have positive values that slowly decrease as the lags increase.\index{autocorrelation}

When data are seasonal,\index{seasonality} the autocorrelations will be larger for the seasonal lags (at multiples of the seasonal period) than for other lags.

When data are both trended and seasonal, you see a combination of these effects. The `a10` data plotted in Figure \@ref(fig:a10plot) shows both trend and seasonality. Its ACF is shown in Figure \@ref(fig:acfa10).\index{autocorrelation} The slow decrease in the ACF as the lags increase is due to the trend, while the "scalloped" shape is due to the seasonality.\index{autocorrelation}\enlargethispage*{0.5cm}

```{r acfa10, echo=TRUE, fig.cap="ACF of monthly Australian antidiabetic drug sales.", fig.asp=0.3, dependson="aelec"}
a10 %>%
  ACF(Cost, lag_max = 48) %>%
  autoplot() +
  labs(title="Australian antidiabetic drug sales")
```

\newpage

## White noise {#wn}

Time series that show no autocorrelation are called **white noise**.\index{white noise} Figure \@ref(fig:wnoise) gives an example of a white noise series.

```{r wnoise, fig.cap="A white noise time series.", fig.asp=0.5}
set.seed(30)
y <- tsibble(sample = 1:50, wn = rnorm(50), index = sample)
y %>% autoplot(wn) + labs(title = "White noise", y = "")
```

```{r wnoiseacf, fig.cap="Autocorrelation function for the white noise series.", fig.asp=0.3, dependson="wnoise"}
y %>%
  ACF(wn) %>%
  autoplot() + labs(title = "White noise")
```

For white noise series, we expect each autocorrelation to be close to zero. Of course, they will not be exactly equal to zero as there is some random variation. For a white noise series, we expect 95% of the spikes in the ACF to lie within $\pm 2/\sqrt{T}$ where $T$ is the length of the time series. It is common to plot these bounds on a graph of the ACF (the blue dashed lines above). If one or more large spikes are outside these bounds, or if substantially more than 5% of spikes are outside these bounds, then the series is probably not white noise.

In this example, $T=50$ and so the bounds are at $\pm 2/\sqrt{50} = \pm `r sprintf("%.2f",2/sqrt(50))`$. All of the autocorrelation coefficients lie within these limits, confirming that the data are white noise.\index{white noise}

## Exercises {#graphics-exercises}

1. Use the help function to explore what the series `gafa_stock`, `PBS`, `vic_elec` and `pelt` represent.

    a. Use `autoplot()` to plot some of the series in these data sets.
    b. What is the time interval of each series?

2. Use `filter()` to find what days corresponded to the peak closing price for each of the four stocks in `gafa_stock`.

3. Download the file `tute1.csv` from [the book website](https://bit.ly/fpptute1), open it in Excel (or some other spreadsheet application), and review its contents. You should find four columns of information. Columns B through D each contain a quarterly series, labelled Sales, AdBudget and GDP. Sales contains the quarterly sales for a small company over the period 1981-2005. AdBudget is the advertising budget and GDP is the gross domestic product. All series have been adjusted for inflation.

    a. You can read the data into R with the following script:

        ```r
        tute1 <- readr::read_csv("tute1.csv")
        View(tute1)
        ```

    b. Convert the data to time series

        ```r
        mytimeseries <- tute1 %>%
          mutate(Quarter = yearquarter(Quarter)) %>%
          as_tsibble(index = Quarter)
        ```

    c. Construct time series plots of each of the three series

        ```r
        mytimeseries %>%
          pivot_longer(-Quarter) %>%
          ggplot(aes(x = Quarter, y = value, colour = name)) +
          geom_line() +
          facet_grid(name ~ ., scales = "free_y")
        ```

        Check what happens when you don't include `r if(html){"<code>facet_grid()</code>"}else{"\\verb|facet_grid()|"}`.

4. The `USgas` package contains data on the demand for natural gas in the US.

    a. Install the `USgas` package.
    b. Create a tsibble from `us_total` with year as the index and state as the key.
    c. Plot the annual natural gas consumption by state for the New England area (comprising the states of Maine, Vermont, New Hampshire, Massachusetts, Connecticut and Rhode Island).

5.

    a. Download `tourism.xlsx` from [the book website](https://bit.ly/fpptourism) and read it into R using `readxl::read_excel()`.
    b. Create a tsibble which is identical to the `tourism` tsibble from the `tsibble` package.
    c. Find what combination of `Region` and `Purpose` had the maximum number of overnight trips on average.
    d. Create a new tsibble which combines the Purposes and Regions, and just has total trips by State.

6. Create time plots of the following four time series: `Bricks` from `aus_production`, `Lynx` from `pelt`, `Close` from `gafa_stock`, `Demand` from `vic_elec`.
    + Use `?` (or `help()`) to find out about the data in each series.
    + For the last plot, modify the axis labels and title.

7. The `aus_arrivals` data set comprises quarterly international arrivals to Australia from Japan, New Zealand, UK and the US.
    + Use `autoplot()`, `gg_season()` and `gg_subseries()` to compare the differences between the arrivals from these four countries.
    + Can you identify any unusual observations?

8. Monthly Australian retail data is provided in `aus_retail`. Select one of the time series as follows (but choose your own seed value):

   ```r
   set.seed(12345678)
   myseries <- aus_retail %>%
     filter(`Series ID` == sample(aus_retail$`Series ID`,1))
   ```

   Explore your chosen retail time series using the following functions:

   `autoplot()`, `gg_season()`, `gg_subseries()`, `gg_lag()`,

   `ACF() %>% autoplot()`

   Can you spot any seasonality, cyclicity and trend? What do you learn about the series?

\enlargethispage*{0.4cm}

9. Use the following graphics functions: `autoplot()`, `gg_season()`, `gg_subseries()`, `gg_lag()`, `ACF()` and explore features from the following time series: "Total Private" `Employed` from `us_employment`, `Bricks` from `aus_production`, `Hare` from `pelt`, "H02" `Cost` from `PBS`, and `us_gasoline`.
    + Can you spot any seasonality, cyclicity and trend?
    + What do you learn about the series?
    + What can you say about the seasonal patterns?
    + Can you identify any unusual years?

10. The following time plots and ACF plots correspond to four different time series. Your task is to match each time plot in the first row with one of the ACF plots in the second row.

    ```{r acfguess, fig.asp=0.45, fig.width=10, echo=FALSE, message=FALSE, warning=FALSE, out.width="135%"}
cowtemp <- as_tsibble(fma::cowtemp)
USAccDeaths <- as_tsibble(USAccDeaths)
AirPassengers <- as_tsibble(AirPassengers)
mink <- as_tsibble(fma::mink)
tp1 <- autoplot(cowtemp, value) +
  labs(x = "", y = "chirps per minute", title = "1. Daily temperature of cow")
tp2 <- autoplot(USAccDeaths, value) +
  labs(x = "", y = "thousands", title = "2. Monthly accidental deaths")
tp3 <- autoplot(AirPassengers, value) +
  labs(x = "", y = "thousands", title = "3. Monthly air passengers")
tp4 <- autoplot(mink, value) +
  labs(x = "", y = "thousands", title = "4. Annual mink trappings")
acfb <- ACF(cowtemp, value) %>%
  autoplot() +
  labs(x = "", title = "B") +
  ylim(-0.45, 1)
acfa <- ACF(USAccDeaths, value) %>%
  autoplot() +
  labs(x = "", title = "A") +
  ylim(-0.45, 1)
acfd <- ACF(AirPassengers, value) %>%
  autoplot() +
  labs(x = "", title = "D") +
  ylim(-0.45, 1)
acfc <- ACF(mink, value) %>%
  autoplot() +
  labs(x = "", title = "C") +
  ylim(-0.45, 1)
(tp1 / acfa) | (tp2 / acfb) | (tp3 / acfc) | (tp4 / acfd)
    ```

11. The `aus_livestock` data contains the monthly total number of pigs slaughtered in Victoria, Australia, from Jul 1972 to Dec 2018. Use `filter()` to extract pig slaughters in Victoria between 1990 and 1995. Use `autoplot()` and `ACF()` for this data. How do they differ from white noise? If a longer period of data is used, what difference does it make to the ACF?

12.

    a. Use the following code to compute the daily changes in Google closing stock prices.

       ```r
       dgoog <- gafa_stock %>%
         filter(Symbol == "GOOG", year(Date) >= 2018) %>%
         mutate(trading_day = row_number()) %>%
         update_tsibble(index = trading_day, regular = TRUE) %>%
         mutate(diff = difference(Close))
       ```

    b. Why was it necessary to re-index the tsibble?
    c. Plot these differences and their ACF.
    d. Do the changes in the stock prices look like white noise?

## Further reading {#graphics-reading}

 * @Cleveland1993 is a classic book on the principles of visualisation for data analysis. While it is more than 20 years old, the ideas are timeless.
 * @Unwin2015 is a modern introduction to graphical data analysis using R. It does not have much information on time series graphics, but plenty of excellent general advice on using graphics for data analysis.

\index{time series graphics|)}
